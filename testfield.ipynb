{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步 先找到要下载的论文。`2203.04114`就是论文的id，22 表示是22年的论文，03表示是3月的论文，后面的04114就是论文的编号。我们想得到这篇论文里面的所有公式，但是原始的PDF文档不能得到公式对应的`mathjax`语法\n",
    "比如刚才看到的公式语法如下：\n",
    "`L=-\\sum_{i=1}^{10}y_i \\log p_i`\n",
    "对应的渲染结果就是：\n",
    "$$\n",
    "L=-\\sum_{i=1}^{10}y_i \\log p_i\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好在arxiv收录了它的latex源文件工程，因此可以从其中提取公式的mathjax表达。先下载回来看看长啥样："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用了一个`get`请求`https://arxiv.org/e-print/2203.04114`，可以看到这个源文件和文件id是对应的，不放心的话可以多找几个来看看，像刚刚那种就没有latex文件 我们直接放弃。看看下载的文件。他应该是`.tar.gz`格式的文件我们重命名一下"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，`\\begin{equation}\\bm{E}_\\text{V} = f_V(\\bm{I_\\text{V}}).\\end{equation}`间的内容就是公式，我们需要提取这部分的内容。重新整理下思路，首先得到paper的id后，下载文件并重命名->解压->找到`.tex`文件\n",
    "-> 找到latex公式对应的数据->保存。一份论文大概有1Mb左右的大小，大量处理的时候记得及时清理数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: 找到paper的id。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后面的参数，有一个skip和show，show应该是指每页展示的paper数，skip就是跳过多少个paper，还有能看到有些paper是没有源文件的。我们筛选那些有源文件的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://arxiv.org/list/cs/2001?skip=0&show=100'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 Edg/108.0.1462.54'\n",
    "}\n",
    "req = requests.get(url,headers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个页最好别显示太多，不然加载和解析会很慢，下面获取有format的index。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python3.9\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(req.text, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001.00003\n",
      "2001.00004\n",
      "2001.00006\n",
      "2001.00008\n",
      "2001.00009\n",
      "2001.00046\n",
      "2001.00047\n",
      "2001.00048\n",
      "2001.00051\n",
      "2001.00053\n"
     ]
    }
   ],
   "source": [
    "results = soup.find_all('a', title = 'Other formats' )\n",
    "for each in results[:10]:\n",
    "    print(each.get('href')[8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_id = [each.get('href')[8:] for each in results]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面用一个表格记录一下这些合法的paper："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['paper_id'] = papers_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001.00009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id\n",
       "0  2001.00003\n",
       "1  2001.00004\n",
       "2  2001.00006\n",
       "3  2001.00008\n",
       "4  2001.00009"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拿到了id后可以下载回来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = papers_id[0]\n",
    "def download_tar(file_name, dir):\n",
    "    '''\n",
    "    下载 file 到 dir\n",
    "    '''\n",
    "    url_base = 'https://arxiv.org/e-print/'\n",
    "    url = url_base + file_name\n",
    "    file_name += '.tar.gz'\n",
    "    file_path = os.path.join(dir, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        print(\"File {} Already Exisist\".format(file_name))\n",
    "        return file_path\n",
    "    else:\n",
    "        req = requests.get(url,headers=headers)\n",
    "        if req.status_code == 200:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(req.content)\n",
    "            print('Finish Download: {}'.format(file_name))\n",
    "            return file_path\n",
    "        else:\n",
    "            print('Download {} Failed.'.format(file_name))\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2001.00003.tar.gz Already Exisist\n"
     ]
    }
   ],
   "source": [
    "tar_file = download_tar(id,'Downloads/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这下载也太慢了，解压一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "def un_tar(file):\n",
    "    tar = tarfile.open(file)\n",
    "    names = tar.getnames()\n",
    "    if os.path.isdir(file + '_files'):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(file + '_files')\n",
    "        for name in names:\n",
    "            tar.extract(name, file + '_files')\n",
    "    return file + '_files'\n",
    "\n",
    "untar_file = un_tar(tar_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面就要找到其中的tex文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def find_texs(untar_file):\n",
    "    texs = glob.glob('{}/*.tex'.format(untar_file))\n",
    "    return texs\n",
    "texs = find_texs(untar_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一步解析latex公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_tex(file):\n",
    "    rule = re.compile(r'\\\\begin{equation}(.*?)\\\\end{equation}',re.S)\n",
    "    with open(file, 'rb') as f:\n",
    "        content = f.read().decode('utf-8')\n",
    "        content = content.replace('\\n','')\n",
    "        results = rule.findall(content)\n",
    "    return results\n",
    "    \n",
    "formula = parse_tex(texs[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者直接把一篇文章的所有tex文件中的公式保存起来。用正则筛选，多行匹配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_texs(files):\n",
    "    results = []\n",
    "    rule = re.compile(r'\\\\begin{equation}(.*?)\\\\end{equation}',re.S)\n",
    "    for file in files:\n",
    "        with open(file, 'rb') as f:\n",
    "            content = f.read().decode('utf-8')\n",
    "            content = content.replace('\\n','')\n",
    "            result = rule.findall(content)\n",
    "        results += result\n",
    "    return {index:value for index, value in enumerate(results)}\n",
    "    \n",
    "formula = parse_texs(texs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后把已经提取好的文件删除省内存。要删除`tar`文件和解压后的`tar_files`文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def clean_files(file):\n",
    "    # 以id作为标识\n",
    "    # 先删除文件夹\n",
    "    shutil.rmtree(untar_file)\n",
    "    os.remove(tar_file)\n",
    "clean_files(id[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整个流程过完了，可以整合到一起了。哦对还要把资料保存到`DataFrame`里："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001.00009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id\n",
       "0  2001.00003\n",
       "1  2001.00004\n",
       "2  2001.00006\n",
       "3  2001.00008\n",
       "4  2001.00009"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data.iterrows():\n",
    "    data['formula'] = str(formula)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001.00003</td>\n",
       "      <td>{0: '    e(n) =  \\\\cdot \\\\sum_{p \\\\in \\\\mathbb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001.00004</td>\n",
       "      <td>{0: '    e(n) =  \\\\cdot \\\\sum_{p \\\\in \\\\mathbb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001.00006</td>\n",
       "      <td>{0: '    e(n) =  \\\\cdot \\\\sum_{p \\\\in \\\\mathbb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001.00008</td>\n",
       "      <td>{0: '    e(n) =  \\\\cdot \\\\sum_{p \\\\in \\\\mathbb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001.00009</td>\n",
       "      <td>{0: '    e(n) =  \\\\cdot \\\\sum_{p \\\\in \\\\mathbb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                            formula\n",
       "0  2001.00003  {0: '    e(n) =  \\\\cdot \\\\sum_{p \\\\in \\\\mathbb...\n",
       "1  2001.00004  {0: '    e(n) =  \\\\cdot \\\\sum_{p \\\\in \\\\mathbb...\n",
       "2  2001.00006  {0: '    e(n) =  \\\\cdot \\\\sum_{p \\\\in \\\\mathbb...\n",
       "3  2001.00008  {0: '    e(n) =  \\\\cdot \\\\sum_{p \\\\in \\\\mathbb...\n",
       "4  2001.00009  {0: '    e(n) =  \\\\cdot \\\\sum_{p \\\\in \\\\mathbb..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7acb2566f01bf27888f586609b378558894aa82f04dc781041790cf6d0c45f57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
